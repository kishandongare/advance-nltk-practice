{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc9feb8a",
   "metadata": {},
   "source": [
    "# VECTORIZATION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69e93df",
   "metadata": {},
   "source": [
    "# Scikit-learn CountVectorizer in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb9c900",
   "metadata": {},
   "source": [
    "Whenever we work on any NLP related problem, we process a lot of textual data. The textual data after processing needs to be fed into the model. Since the model doesn't accept textual data and only understands numbers, this data needs to be vectorized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de6ef5",
   "metadata": {},
   "source": [
    "# Bag of Words(BoW) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d12429e",
   "metadata": {},
   "source": [
    ">we cannot pass text directly to train our models in Natural Language Processing, \n",
    "thus we need to convert it into numbers, which machine can understand and can perform\n",
    "the required modelling on it. \n",
    "\n",
    ">The Bag of Words(BoW) model is a fundamental(and old) way\n",
    "of doing this.\n",
    "\n",
    ">The BoW model is very simple as it discards all the information and order of the text and just considers the occurrences of the word, in short it converts a sentence or a paragraph into a bag of words with no meaning.\n",
    "\n",
    ">It converts the sentence or a paragraph into a fixed-length vector of numbers.\n",
    "\n",
    ">The BoW model is very simple as it discards all the information and order of the text and just considers the occurrences of the word, in short it converts a sentence or a paragraph into a bag of words with no meaning. \n",
    "\n",
    ">It converts the documents to a fixed-length vector of numbers.\n",
    "\n",
    ">A unique number is assigned to each word(generally index of an array) along with the count representing the number of occurence of that word.\n",
    "\n",
    ">This is the encoding of the words, in which we are focusing on the representation of the word and not on the order of the word.\n",
    "\n",
    ">There are multiple ways with which we can define what this 'encoding' would be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac12acc7",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e218a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb11ec0b",
   "metadata": {},
   "source": [
    " >CountVectorizer tokenizes(tokenization means breaking down a sentence or paragraph or any text into words) the text along with performing very basic preprocessing like removing the punctuation marks, converting all the words to lowercase, etc.\n",
    "\n",
    ">The vocabulary of known words is formed which is also used for encoding unseen text later.\n",
    "\n",
    ">An encoded vector is returned with a length of the entire vocabulary and an integer count for the number of times each word appeared in the document. Let's take an example to see how it works.\n",
    "\n",
    "> sentence: <<Out of all the countries of the world, some countries are poor, some countries are rich, but no country is perfect.>>\n",
    "\n",
    ">if dataset is huge then there is huge unique words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c24da3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://user-images.githubusercontent.com/66677660/146169380-02d36974-b86b-4fac-a0f0-92a633a7184f.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://user-images.githubusercontent.com/66677660/146169380-02d36974-b86b-4fac-a0f0-92a633a7184f.png\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e0b277",
   "metadata": {},
   "source": [
    "\n",
    ">From the tables above we can see the CountVectorizer sparse matrix representation of words. Table A is how you visually think about it while Table B is how it is represented in practice.\n",
    "\n",
    ">The row of the above matrix represents the document, and the columns contain all the unique words with their frequency. In case a word did not occur, then it is assigned zero correspondings to the document in a row.\n",
    "\n",
    ">Imagine it as a one-hot encoded vector and due to that, it is pretty obvious to get a sparse matrix with a lot of zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Lower case\n",
    "\n",
    "#2.Tokenization\n",
    "\n",
    "#3.Removing special characters isalnum()\n",
    "\n",
    "#4.Removing stop words and punctuation\n",
    "\n",
    "#5.Stemming\n",
    "\n",
    "#6.word replacement wont-> will not\n",
    "\n",
    "https://github.com/kishandongare/advance-nltk-practice/blob/main/nltk_part1.ipynb\n",
    "\n",
    "#7.vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cabbc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For huge dataset the vector is in this form.the shape of dataset = No. of vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700c7586",
   "metadata": {},
   "source": [
    "please visit this link\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f4e1b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c896f506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "(5, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['19',\n",
       " 'access',\n",
       " 'aim',\n",
       " 'ask',\n",
       " 'collaboration',\n",
       " 'commit',\n",
       " 'community',\n",
       " 'consequences',\n",
       " 'covid',\n",
       " 'deployment',\n",
       " 'devastating',\n",
       " 'donors',\n",
       " 'economic',\n",
       " 'equitable',\n",
       " 'expedite',\n",
       " 'fight',\n",
       " 'global',\n",
       " 'initiatives',\n",
       " 'innovative',\n",
       " 'investment',\n",
       " 'landmark',\n",
       " 'leaders',\n",
       " 'left',\n",
       " 'ongoing',\n",
       " 'political',\n",
       " 'shared',\n",
       " 'social',\n",
       " 'support',\n",
       " 'tools',\n",
       " 'world']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = [\"devastating social and economic economic consequences of COVID-19\",\n",
    "\"economic COVID-19 investment and initiatives already ongoing around the world to expedite deployment of innovative COVID-19\",\n",
    "\"We commit to the shared aim of equitable global access to innovative tools for COVID-19 for all\",\n",
    "\"We ask the global community and political leaders to support this landmark collaboration, and for donors\",\n",
    "\"In the fight against COVID-19, no one should be left behind\"]\n",
    "\n",
    "cv = CountVectorizer(document,stop_words=('english'))\n",
    "cv_vector = cv.fit_transform(document)\n",
    "\n",
    "print(len(cv.get_feature_names()))\n",
    "print(cv_vector.shape)\n",
    "\n",
    "#In case you are wondering what get_feature_names would return \n",
    "\n",
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22a23502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape returned (5,30) means 5 rows(sentences) and 30 columns(unique words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dc0f1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fc19aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc_Term_Matrix = pd.DataFrame(cv_vector.toarray(),columns= cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68071a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>19</th>\n",
       "      <th>access</th>\n",
       "      <th>aim</th>\n",
       "      <th>ask</th>\n",
       "      <th>collaboration</th>\n",
       "      <th>commit</th>\n",
       "      <th>community</th>\n",
       "      <th>consequences</th>\n",
       "      <th>covid</th>\n",
       "      <th>deployment</th>\n",
       "      <th>...</th>\n",
       "      <th>landmark</th>\n",
       "      <th>leaders</th>\n",
       "      <th>left</th>\n",
       "      <th>ongoing</th>\n",
       "      <th>political</th>\n",
       "      <th>shared</th>\n",
       "      <th>social</th>\n",
       "      <th>support</th>\n",
       "      <th>tools</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   19  access  aim  ask  collaboration  commit  community  consequences  \\\n",
       "0   1       0    0    0              0       0          0             1   \n",
       "1   2       0    0    0              0       0          0             0   \n",
       "2   1       1    1    0              0       1          0             0   \n",
       "3   0       0    0    1              1       0          1             0   \n",
       "4   1       0    0    0              0       0          0             0   \n",
       "\n",
       "   covid  deployment  ...  landmark  leaders  left  ongoing  political  \\\n",
       "0      1           0  ...         0        0     0        0          0   \n",
       "1      2           1  ...         0        0     0        1          0   \n",
       "2      1           0  ...         0        0     0        0          0   \n",
       "3      0           0  ...         1        1     0        0          1   \n",
       "4      1           0  ...         0        0     1        0          0   \n",
       "\n",
       "   shared  social  support  tools  world  \n",
       "0       0       1        0      0      0  \n",
       "1       0       0        0      0      1  \n",
       "2       1       0        0      1      0  \n",
       "3       0       0        1      0      0  \n",
       "4       0       0        0      0      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Doc_Term_Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85898fa",
   "metadata": {},
   "source": [
    "https://www.studytonight.com/post/scikitlearn-countvectorizer-in-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb574ad",
   "metadata": {},
   "source": [
    "https://iksinc.online/tag/countvectorizer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb26f157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
